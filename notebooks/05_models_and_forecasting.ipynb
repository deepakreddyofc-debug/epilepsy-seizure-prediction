{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91c2f770-7648-465c-999e-a968984cb19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5760, 69)\n",
      "labels shape: (5760,)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "processed_dir = Path(\"../data_processed\")\n",
    "\n",
    "X      = np.load(processed_dir / \"X.npy\")\n",
    "labels = np.load(processed_dir / \"labels.npy\")\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2fec19e-7d03-46b5-b15b-7655ea9bc3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea66e475-3c77-4b44-8723-82e4d471da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy: 0.8862847222222222\n",
      "ROC-AUC: 0.42673325806909856\n",
      "\n",
      "SVM\n",
      "Accuracy: 0.8897569444444444\n",
      "ROC-AUC: 0.799754768188649\n",
      "\n",
      "MLP\n",
      "Accuracy: 0.8862847222222222\n",
      "ROC-AUC: 0.5765826049898692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 1. Logistic Regression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "lr_prob = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, lr_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, lr_prob))\n",
    "print()\n",
    "\n",
    "# 2. SVM (with probability outputs)\n",
    "svm = SVC(kernel=\"rbf\", probability=True)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "svm_prob = svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"SVM\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, svm_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, svm_prob))\n",
    "print()\n",
    "\n",
    "# 3. MLP\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=300, random_state=42)\n",
    "mlp.fit(X_train, y_train)\n",
    "mlp_pred = mlp.predict(X_test)\n",
    "mlp_prob = mlp.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"MLP\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, mlp_pred))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, mlp_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aeea151-1897-49c3-bc65-4f27a0de37c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model probabilities!\n"
     ]
    }
   ],
   "source": [
    "results_probabilities = {\n",
    "    \"LR\":  lr_prob,   # logistic regression probabilities\n",
    "    \"SVM\": svm_prob,  # SVM probabilities\n",
    "    \"MLP\": mlp_prob   # neural network probabilities\n",
    "}\n",
    "\n",
    "print(\"Saved model probabilities!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67585238-2095-4a7d-9505-5985e00538b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     prob \u001b[38;5;241m=\u001b[39m results_probabilities[model]\n\u001b[0;32m----> 3\u001b[0m     ss, tiw, bs, bss \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_metrics\u001b[49m(y_test, prob)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mForecasting Metrics for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSS:\u001b[39m\u001b[38;5;124m\"\u001b[39m, ss)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "for model in [\"MLP\"]:\n",
    "    prob = results_probabilities[model]\n",
    "    ss, tiw, bs, bss = compute_metrics(y_test, prob)\n",
    "    print(f\"\\nForecasting Metrics for {model}:\")\n",
    "    print(\"SS:\", ss)\n",
    "    print(\"TIW:\", tiw)\n",
    "    print(\"Brier Score:\", bs)\n",
    "    print(\"Brier Skill Score:\", bss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43a9296c-91c7-4faf-ac8f-e95de737ef09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (5760, 69)\n",
      "labels shape: (5760,)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "processed_dir = Path(\"../data_processed\")\n",
    "\n",
    "# Get all feature files for chb01\n",
    "feature_files = sorted(f for f in processed_dir.glob(\"chb01_*_features.npy\"))\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for f in feature_files:\n",
    "    # load features\n",
    "    X_f = np.load(f)\n",
    "    # load corresponding labels file\n",
    "    labels_f = np.load(processed_dir / f.name.replace(\"_features\", \"_labels\"))\n",
    "    \n",
    "    X_list.append(X_f)\n",
    "    y_list.append(labels_f)\n",
    "\n",
    "# Stack everything into one big matrix\n",
    "X = np.vstack(X_list)\n",
    "labels = np.concatenate(y_list)\n",
    "\n",
    "print(\"X shape:\", X.shape)        # should be (5760, 69)\n",
    "print(\"labels shape:\", labels.shape)  # (5760,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e000b04-9a3f-4ba1-b3de-1d6140e6aed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Accuracy: 0.8862847222222222\n",
      "LR ROC-AUC: 0.42673325806909856\n",
      "\n",
      "SVM Accuracy: 0.8897569444444444\n",
      "SVM ROC-AUC: 0.799754768188649\n",
      "\n",
      "MLP Accuracy: 0.8862847222222222\n",
      "MLP ROC-AUC: 0.6384027035311886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# ---------- Logistic Regression ----------\n",
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "lr_prob = lr_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"LR Accuracy:\", accuracy_score(y_test, lr_pred))\n",
    "print(\"LR ROC-AUC:\", roc_auc_score(y_test, lr_prob))\n",
    "\n",
    "# ---------- SVM ----------\n",
    "svm_clf = SVC(kernel=\"rbf\", probability=True)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "svm_pred = svm_clf.predict(X_test)\n",
    "svm_prob = svm_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nSVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
    "print(\"SVM ROC-AUC:\", roc_auc_score(y_test, svm_prob))\n",
    "\n",
    "# ---------- MLP ----------\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=200)\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "mlp_pred = mlp_clf.predict(X_test)\n",
    "mlp_prob = mlp_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nMLP Accuracy:\", accuracy_score(y_test, mlp_pred))\n",
    "print(\"MLP ROC-AUC:\", roc_auc_score(y_test, mlp_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19cfd58e-7f12-429b-b11d-3393bf678b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, prob, window_size_sec=5, threshold=0.7):\n",
    "    \"\"\"\n",
    "    y_true : 0/1 labels per window\n",
    "    prob   : predicted probabilities per window\n",
    "    window_size_sec : length of each window (5 s here)\n",
    "    threshold : firing power threshold -> warning state\n",
    "    \n",
    "    Returns:\n",
    "        SS   : Seizure Sensitivity (TPR)\n",
    "        FPRh : False Positives per Hour\n",
    "        TiW  : Time in Warning (fraction of time in alarm)\n",
    "        BS   : Brier Score\n",
    "        BSS  : Brier Skill Score\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    y_true = np.asarray(y_true)\n",
    "    prob = np.asarray(prob)\n",
    "\n",
    "    # Warning state based on probability threshold\n",
    "    warn = (prob >= threshold).astype(int)\n",
    "\n",
    "    # --- SS (sensitivity = TPR on seizure windows) ---\n",
    "    tp = np.sum((warn == 1) & (y_true == 1))\n",
    "    fn = np.sum((warn == 0) & (y_true == 1))\n",
    "    ss = tp / (tp + fn + 1e-9)\n",
    "\n",
    "    # --- FPR per hour ---\n",
    "    fp = np.sum((warn == 1) & (y_true == 0))\n",
    "    hours = len(y_true) * window_size_sec / 3600.0\n",
    "    fpr_h = fp / (hours + 1e-9)\n",
    "\n",
    "    # --- Time in Warning (fraction of windows in alarm) ---\n",
    "    tiw = warn.mean()\n",
    "\n",
    "    # --- Brier score ---\n",
    "    bs = np.mean((prob - y_true) ** 2)\n",
    "\n",
    "    # --- Brier Skill Score (vs climatology) ---\n",
    "    p = y_true.mean()\n",
    "    bs_ref = np.mean((p - y_true) ** 2)\n",
    "    bss = 1.0 - bs / (bs_ref + 1e-9)\n",
    "\n",
    "    return ss, fpr_h, tiw, bs, bss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b363d5a-ab60-4696-b767-3791472bea7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model probabilities!\n"
     ]
    }
   ],
   "source": [
    "results_probabilities = {\n",
    "    \"LR\": lr_prob,   # logistic regression probabilities\n",
    "    \"SVM\": svm_prob, # SVM probabilities\n",
    "    \"MLP\": mlp_prob  # neural network probabilities\n",
    "}\n",
    "\n",
    "print(\"Saved model probabilities!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b340933b-8ca8-4bb0-97c5-b7c1f9adda5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Forecasting Metrics for LR:\n",
      "SS      : 0.0\n",
      "FPR/h   : 0.0\n",
      "TiW     : 0.0\n",
      "Brier   : 0.10078419571713916\n",
      "Brier SS: -8.070660646453121e-07\n",
      "\n",
      "Forecasting Metrics for SVM:\n",
      "SS      : 0.09160305343441526\n",
      "FPR/h   : 0.6249999996093749\n",
      "TiW     : 0.011284722222222222\n",
      "Brier   : 0.08177510880687788\n",
      "Brier SS: 0.1886111287299126\n",
      "\n",
      "Forecasting Metrics for MLP:\n",
      "SS      : 0.0\n",
      "FPR/h   : 0.0\n",
      "TiW     : 0.0\n",
      "Brier   : 0.10078383412590834\n",
      "Brier SS: 2.780713944772195e-06\n"
     ]
    }
   ],
   "source": [
    "for model_name in [\"LR\", \"SVM\", \"MLP\"]:\n",
    "    prob = results_probabilities[model_name]\n",
    "    ss, fpr_h, tiw, bs, bss = compute_metrics(y_test, prob)\n",
    "\n",
    "    print(f\"\\nForecasting Metrics for {model_name}:\")\n",
    "    print(\"SS      :\", ss)\n",
    "    print(\"FPR/h   :\", fpr_h)\n",
    "    print(\"TiW     :\", tiw)\n",
    "    print(\"Brier   :\", bs)\n",
    "    print(\"Brier SS:\", bss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef65d08-e187-4aea-a1ac-fe3fd644fcfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (epilepsy-ml)",
   "language": "python",
   "name": "epilepsy-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
